{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsXME6B+xTHAoZ+9zlGFea",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiri9/Federated-Machine-Learning/blob/main/FL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLCf-P7n4nlG",
        "outputId": "58890bbe-4e4d-41e0-9514-3540986e8b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.4/200.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "#from torchvision.datasets import MNIST\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset, random_split\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr.common.typing import NDArrays, Scalar\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "694Z6FJs4ynR",
        "outputId": "aebae6ed-85f7-4040-f15a-02ad1ecdd7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.0.1+cu118 and Flower 1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VayP31HX48uz",
        "outputId": "5d90e69c-77ce-4d36-bea9-a8904b79cc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "\n",
        "\n",
        "#reading training csv file from google drive\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_train.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/kdd_test.csv')\n",
        "\n",
        "#creating copies of datasets\n",
        "df_train_copy = df_train.copy()\n",
        "df_test_copy = df_test.copy()\n",
        "\n",
        "#Encoding categories in 0-Normal, 1-DoS, 2-Probe, 3-R2L, 4-U2R\n",
        "df1_train_labels = df_train_copy['labels']\n",
        "df1_train_labels_in_numbers = df1_train_labels.replace({ 'normal' : 0, 'neptune' : 1,'land' : 1, 'back': 1, 'teardrop': 1, 'pod': 1, 'smurf' : 1,\n",
        "                                                     'ipsweep' : 2, 'nmap' : 2, 'portsweep' : 2, 'satan' : 2,\n",
        "                                                     'phf': 3, 'multihop': 3, 'warezclient': 3,'warezmaster': 3, 'spy': 3, 'ftp_write' : 3,\n",
        "                                                     'guess_passwd': 3,'imap': 3,\n",
        "                                                     'buffer_overflow': 4, 'loadmodule': 4,'perl': 4,  'rootkit': 4 })\n",
        "#replacing the string output clsses by numbers\n",
        "df_train_copy['labels'] = df1_train_labels_in_numbers\n",
        "\n",
        "#Encoding categories in 0-Normal, 1-DoS, 2-Probe, 3-R2L, 4-U2R\n",
        "df1_test_labels = df_test_copy['labels']\n",
        "df1_test_labels_in_numbers = df1_test_labels.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1,\n",
        "                                                      'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1,\n",
        "                                                     'ipsweep' : 2, 'nmap' : 2, 'portsweep' : 2, 'satan' : 2, 'mscan' : 2,'saint' : 2,\n",
        "                                                     'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3, 'warezclient': 3,\n",
        "                                                       'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,\n",
        "                                                       'xsnoop': 3,'httptunnel': 3,\n",
        "                                                     'buffer_overflow': 4, 'loadmodule': 4,'perl': 4,  'rootkit': 4, 'ps': 4,'xterm': 4 })\n",
        "#replacing the string output clsses by numbers\n",
        "df_test_copy['labels'] = df1_test_labels_in_numbers\n",
        "\n",
        "#Transform categorical features into numbers using LabelEncoder() from train dataset\n",
        "dft = df_train_copy.apply(LabelEncoder().fit_transform)\n",
        "df_train_copy = dft\n",
        "\n",
        "#Transform categorical features into numbers using LabelEncoder() from test dataset\n",
        "dftt = df_test_copy.apply(LabelEncoder().fit_transform)\n",
        "df_test_copy = dftt\n",
        "\n",
        "# Dropping the column \"num_outbound_cmds\" from train and test datasets\n",
        "df_train_copy = df_train_copy.drop('num_outbound_cmds', axis=1)\n",
        "df_test_copy = df_test_copy.drop('num_outbound_cmds', axis=1)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Select the columns to be normalized (assuming they are numerical features)\n",
        "numerical_columns = ['duration', 'service', 'flag', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate',\n",
        "                     'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                     'dst_host_same_src_port_rate','dst_host_serror_rate', 'dst_host_srv_serror_rate', 'rerror_rate',\n",
        "                     'srv_rerror_rate','diff_srv_rate', 'srv_diff_host_rate', 'dst_host_srv_diff_host_rate',\n",
        "                     'dst_host_rerror_rate', 'dst_host_srv_rerror_rate','hot','num_compromised','num_root',]\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler to the selected columns\n",
        "scaler.fit(df_train_copy[numerical_columns])\n",
        "\n",
        "# Transform the selected columns with the scaler\n",
        "df_train_copy[numerical_columns] = scaler.transform(df_train_copy[numerical_columns])\n",
        "\n",
        "# Select the columns to be normalized (assuming they are numerical features)\n",
        "numerical_columns = ['duration', 'service', 'flag', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'same_srv_rate',\n",
        "                     'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                     'dst_host_same_src_port_rate','dst_host_serror_rate', 'dst_host_srv_serror_rate', 'rerror_rate',\n",
        "                     'srv_rerror_rate','diff_srv_rate', 'srv_diff_host_rate', 'dst_host_srv_diff_host_rate',\n",
        "                     'dst_host_rerror_rate', 'dst_host_srv_rerror_rate','hot','num_compromised','num_root',]\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler to the selected columns\n",
        "scaler.fit(df_test_copy[numerical_columns])\n",
        "\n",
        "# Transform the selected columns with the scaler\n",
        "df_test_copy[numerical_columns] = scaler.transform(df_test_copy[numerical_columns])"
      ],
      "metadata": {
        "id": "F6V_PbdJ5Fc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_copy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b7xYQPwOpj3",
        "outputId": "cd6ef155-9de1-4235-ac0c-17ebd5ddca27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125973, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of partitions\n",
        "num_partitions = 10\n",
        "\n",
        "# Split your DataFrame into 10 partitions\n",
        "partition_size = len(df_train_copy) // num_partitions\n",
        "data_partitions = []\n",
        "\n",
        "for i in range(num_partitions):\n",
        "    start_index = i * partition_size\n",
        "    end_index = (i + 1) * partition_size if i < num_partitions - 1 else len(df_train_copy)\n",
        "    partition = df_train_copy.iloc[start_index:end_index]\n",
        "    data_partitions.append(partition)\n",
        "\n",
        "# Create DataLoaders for each partition with validation datasets\n",
        "batch_size = 32  # Set your desired batch size\n",
        "dataloaders = []\n",
        "val_loaders = []\n",
        "\n",
        "for partition in data_partitions:\n",
        "    # Split each partition into training and validation subsets (90% train, 10% validation)\n",
        "    len_partition = len(partition)\n",
        "    len_train = int(0.9 * len_partition)\n",
        "    len_val = len_partition - len_train\n",
        "\n",
        "    train_partition, val_partition = random_split(partition, [len_train, len_val], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Prepare training DataLoader\n",
        "    train_features = train_partition.dataset.drop(columns=['labels'])  # Replace 'labels' with your label column name\n",
        "    train_labels = train_partition.dataset['labels']  # Replace 'labels' with your label column name\n",
        "\n",
        "    train_features_tensor = torch.Tensor(train_features.values)\n",
        "    train_labels_tensor = torch.Tensor(train_labels.values)\n",
        "\n",
        "    train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Prepare validation DataLoader\n",
        "    val_features = val_partition.dataset.drop(columns=['labels'])  # Replace 'labels' with your label column name\n",
        "    val_labels = val_partition.dataset['labels']  # Replace 'labels' with your label column name\n",
        "\n",
        "    val_features_tensor = torch.Tensor(val_features.values)\n",
        "    val_labels_tensor = torch.Tensor(val_labels.values)\n",
        "\n",
        "    val_dataset = TensorDataset(val_features_tensor, val_labels_tensor)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    dataloaders.append(train_dataloader)\n",
        "    val_loaders.append(val_dataloader)\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_features = df_test_copy.drop(columns=['labels'])  # Replace 'labels' with your label column name\n",
        "test_labels = df_test_copy['labels']  # Replace 'labels' with your label column name\n",
        "\n",
        "test_features_tensor = torch.Tensor(test_features.values)\n",
        "test_labels_tensor = torch.Tensor(test_labels.values)\n",
        "\n",
        "test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Now 'dataloaders' is a list of training DataLoaders, 'val_loaders' is a list of validation DataLoaders,\n",
        "# and 'test_dataloader' is the DataLoader for the test dataset.\n",
        "# Each partition has its own training and validation DataLoader.\n",
        "# You can use these for federated learning, and validation during training, and testing.\n"
      ],
      "metadata": {
        "id": "1wkXWPX7O4iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define your layers here\n",
        "        self.fc1 = nn.Linear(40, 128)  # 40 input features, 128 hidden units\n",
        "        self.fc2 = nn.Linear(128, 64)  # 128 hidden units, 64 hidden units\n",
        "        self.fc3 = nn.Linear(64, 5)   # 64 hidden units, 5 output classes (assuming you have 5 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward pass\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uXq7eTlCJGrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
        "\n",
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for data, labels in trainloader:\n",
        "            data, labels = data.to(DEVICE), labels.long().to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, labels in testloader:\n",
        "            data, labels = data.to(DEVICE), labels.long().to(DEVICE)\n",
        "            outputs = net(data)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            total += labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "6y42WuGZSAzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = dataloaders[0]\n",
        "valloader = val_loaders[0]\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train(net, dataloader, 1)\n",
        "    loss, accuracy = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(net, test_dataloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vgn3XKClQXA",
        "outputId": "8cba2ae2-f782-4103-fae9-d45de80180db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: validation loss 0.10319055386861493, accuracy 0.9641184408986266\n",
            "Epoch 2: validation loss 0.05248350328541252, accuracy 0.9826942922918155\n",
            "Epoch 3: validation loss 0.043891022792015094, accuracy 0.9831705961736922\n",
            "Epoch 4: validation loss 0.039717575257731515, accuracy 0.9856314995633881\n",
            "Epoch 5: validation loss 0.034481892669378414, accuracy 0.9888862427562118\n",
            "Final test set performance:\n",
            "\tloss 0.4982836263024757\n",
            "\taccuracy 0.9177164655784245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "id": "eIAth4l2XElq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ],
      "metadata": {
        "id": "r5FA_J-7XS9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = dataloaders[int(cid)]\n",
        "    valloader = val_loaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "rW_bAAbjXXRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "    min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "id": "_mduv2DiXpbB",
        "outputId": "7a08aeee-8443-4159-bc24-cd096b92552f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-09-16 19:02:15,622 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-09-16 19:02:20,861\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-09-16 19:02:23,534 | app.py:210 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 7800513332.0, 'object_store_memory': 3900256665.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'memory': 7800513332.0, 'object_store_memory': 3900256665.0}\n",
            "INFO flwr 2023-09-16 19:02:23,545 | app.py:218 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-09-16 19:02:23,551 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-09-16 19:02:23,634 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-09-16 19:02:23,638 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-09-16 19:02:23,656 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=10385)\u001b[0m 2023-09-16 19:02:32.907595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-09-16 19:02:39,009 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-09-16 19:02:39,012 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-09-16 19:02:39,015 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-09-16 19:02:39,017 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10387)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[2m\u001b[36m(pid=10387)\u001b[0m 2023-09-16 19:02:32.907595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10385)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=10385)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "DEBUG flwr 2023-09-16 19:03:08,856 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-09-16 19:03:08,880 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-09-16 19:03:08,884 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:03:15,693 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 5 results and 0 failures\n",
            "WARNING flwr 2023-09-16 19:03:15,701 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-09-16 19:03:15,704 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:03:41,286 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:03:41,324 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:03:50,536 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:03:50,544 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:04:12,947 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:04:12,975 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:04:23,157 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:04:23,166 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:04:50,505 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:04:50,533 | server.py:173 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:05:00,222 | server.py:187 | evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:05:00,226 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:05:23,479 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:05:23,501 | server.py:173 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:05:30,348 | server.py:187 | evaluate_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 5 results and 0 failures\n",
            "INFO flwr 2023-09-16 19:05:30,353 | server.py:153 | FL finished in 171.33547567300002\n",
            "INFO:flwr:FL finished in 171.33547567300002\n",
            "INFO flwr 2023-09-16 19:05:30,363 | app.py:225 | app_fit: losses_distributed [(1, 0.09261210093009971), (2, 0.0490265913844241), (3, 0.03936922288356322), (4, 0.03672530524965466), (5, 0.03144549798841955)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.09261210093009971), (2, 0.0490265913844241), (3, 0.03936922288356322), (4, 0.03672530524965466), (5, 0.03144549798841955)]\n",
            "INFO flwr 2023-09-16 19:05:30,367 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-09-16 19:05:30,370 | app.py:227 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-09-16 19:05:30,373 | app.py:228 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-09-16 19:05:30,375 | app.py:229 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.09261210093009971\n",
              "\tround 2: 0.0490265913844241\n",
              "\tround 3: 0.03936922288356322\n",
              "\tround 4: 0.03672530524965466\n",
              "\tround 5: 0.03144549798841955"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "8P0ZWA_FYoZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "id": "lHOEOJVcYqmv",
        "outputId": "13021196-2d9c-412e-f296-3f34ee8585c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-09-16 19:06:16,265 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-09-16 19:06:24,456\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-09-16 19:06:27,226 | app.py:210 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7788785664.0, 'object_store_memory': 3894392832.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'memory': 7788785664.0, 'object_store_memory': 3894392832.0}\n",
            "INFO flwr 2023-09-16 19:06:27,231 | app.py:218 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2023-09-16 19:06:27,233 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2023-09-16 19:06:27,295 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2023-09-16 19:06:27,301 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-09-16 19:06:27,308 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=13149)\u001b[0m 2023-09-16 19:06:32.748141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-09-16 19:06:40,397 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-09-16 19:06:40,401 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-09-16 19:06:40,405 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-09-16 19:06:40,409 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=13149)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=13149)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "\u001b[2m\u001b[36m(pid=13147)\u001b[0m 2023-09-16 19:06:32.827799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=13147)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=13147)\u001b[0m   warnings.warn(_create_warning_msg(\n",
            "DEBUG flwr 2023-09-16 19:07:08,614 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-09-16 19:07:08,638 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-09-16 19:07:08,643 | server.py:173 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:07:17,237 | server.py:187 | evaluate_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:07:17,250 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:07:44,108 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:07:44,131 | server.py:173 | evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:07:51,444 | server.py:187 | evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:07:51,453 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:08:18,739 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:08:18,781 | server.py:173 | evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:08:27,462 | server.py:187 | evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:08:27,465 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:08:52,717 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:08:52,764 | server.py:173 | evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:09:03,295 | server.py:187 | evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:09:03,304 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:09:27,199 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-09-16 19:09:27,224 | server.py:173 | evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 5 clients (out of 10)\n",
            "DEBUG flwr 2023-09-16 19:09:38,518 | server.py:187 | evaluate_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 5 results and 0 failures\n",
            "INFO flwr 2023-09-16 19:09:38,525 | server.py:153 | FL finished in 178.11693285699994\n",
            "INFO:flwr:FL finished in 178.11693285699994\n",
            "INFO flwr 2023-09-16 19:09:38,533 | app.py:225 | app_fit: losses_distributed [(1, 0.10598219948050183), (2, 0.060923484621125124), (3, 0.04669256624357945), (4, 0.03903044099262963), (5, 0.03596093781304405)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.10598219948050183), (2, 0.060923484621125124), (3, 0.04669256624357945), (4, 0.03903044099262963), (5, 0.03596093781304405)]\n",
            "INFO flwr 2023-09-16 19:09:38,535 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-09-16 19:09:38,537 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 0.965961763382816), (2, 0.9819965373463825), (3, 0.9836794172459805), (4, 0.9894419306184012), (5, 0.9889343683492291)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.965961763382816), (2, 0.9819965373463825), (3, 0.9836794172459805), (4, 0.9894419306184012), (5, 0.9889343683492291)]}\n",
            "INFO flwr 2023-09-16 19:09:38,540 | app.py:228 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-09-16 19:09:38,542 | app.py:229 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.10598219948050183\n",
              "\tround 2: 0.060923484621125124\n",
              "\tround 3: 0.04669256624357945\n",
              "\tround 4: 0.03903044099262963\n",
              "\tround 5: 0.03596093781304405\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.965961763382816), (2, 0.9819965373463825), (3, 0.9836794172459805), (4, 0.9894419306184012), (5, 0.9889343683492291)]}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}